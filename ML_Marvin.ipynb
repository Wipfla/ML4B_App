{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "#import tsfresh\n",
    "\n",
    "#Classification with KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFrames(name, pathAcc, pathGyr, pathOri):\n",
    "    df_Acc= pd.read_csv(pathAcc)\n",
    "    df_Gyr= pd.read_csv(pathGyr)\n",
    "    df_Ori= pd.read_csv(pathOri)\n",
    "    print(\"Data Frames for \" + name + \" loaded.\")\n",
    "    return df_Acc, df_Gyr, df_Ori\n",
    "\n",
    "def loadJsonData(name, pathJson):\n",
    "    df = pd.read_json(pathJson)\n",
    "    print(\"Data Frame for \" + name + \" loaded.\")\n",
    "    return df\t   \n",
    "\n",
    "#Concat Funktion\n",
    "def concatDataFrames(name, df_Acc, df_Gyr, df_Ori):\n",
    "  df_Gyr.drop(['time','seconds_elapsed'], axis=1, inplace=True)\n",
    "  df_Ori.drop(['time','seconds_elapsed'], axis=1, inplace=True)\n",
    "  df = pd.concat([df_Acc, df_Gyr, df_Ori], axis=1)\n",
    "  print(\"Data Frames for \" + name + \" concatenated.\")\n",
    "  return df\n",
    "\n",
    "#Function to plot Gyr Data\n",
    "def plotDataGyr(data, title):\n",
    "    plt.plot(data['time'], data['z'], color='red', marker='.')\n",
    "    plt.plot(data['time'], data['y'], color='blue', marker='.')\n",
    "    plt.plot(data['time'], data['x'], color='green', marker='.')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('x,y,z')\n",
    "    plt.legend(['z', 'y', 'x'])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "#Function to Plot Acc Data\n",
    "def plotDataAcc(data, title):\n",
    "    plt.plot(data['time'], data['z'], color='red', marker='.')\n",
    "    plt.plot(data['time'], data['y'], color='blue', marker='.')\n",
    "    plt.plot(data['time'], data['x'], color='green', marker='.')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('x,y,z')\n",
    "    plt.legend(['z', 'y', 'x'])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "#Function to Plot Ori Data\n",
    "def plotDataOri(data, title):\n",
    "    plt.plot(data['time'], data['qz'], color='red', marker='.')\n",
    "    plt.plot(data['time'], data['qy'], color='blue', marker='.')\n",
    "    plt.plot(data['time'], data['qx'], color='green', marker='.')\n",
    "    plt.plot(data['time'], data['qw'], color='yellow', marker='.')\n",
    "    #plt.plot(data['time'], data['roll'], color='black', marker='.')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('qz,qy,qx,qw,roll')\n",
    "    plt.legend(['qz', 'qy', 'qx', 'qw', 'roll'])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "#Clean unused Sensors\n",
    "def deleteSensorData(df):\n",
    "  notUsedSensors = ['Annotation', 'Barometer', 'Battery', 'Brightness', 'Gravity', 'Light', 'Location', 'Magnetometer', 'MagnetometerUncalibrated', 'Microphone']\n",
    "  df = df[~df['sensor'].isin(notUsedSensors)]\n",
    "  #df.drop(['relativeAltitude','pressure', 'batteryLevel', 'batteryState', 'lowPowerMode','brightness', 'lux', 'bearingAccuracy', 'speedAccuracy', 'verticalAccuracy', 'horizontalAccuracy', 'speed', 'bearing','altitude', 'longitude', 'latitude'], axis=1, inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "#Clean Function Json Data\n",
    "def cleanDataJson(df):\n",
    "    #Drop unused Columns\n",
    "    columns_to_drop = ['version','device name','recording time','platform','appVersion', 'device id', 'sampleRateMs','relativeAltitude','pressure', 'batteryLevel', 'batteryState', 'lowPowerMode','brightness', 'lux', 'bearingAccuracy', 'speedAccuracy', 'verticalAccuracy', 'horizontalAccuracy', 'speed', 'bearing','altitude', 'longitude', 'latitude']\n",
    "    columns_to_drop = list(set(columns_to_drop).intersection(df.columns))\n",
    "\n",
    "    if columns_to_drop:\n",
    "        df.drop(columns=columns_to_drop, inplace=True)\n",
    "        print(\"Spalten wurden erfolgreich entfernt.\")\n",
    "    else:\n",
    "        print(\"Keine der Spalten zum Entfernen gefunden.\")\n",
    "        #df.drop(['version','device name','recording time','platform','appVersion', 'device id', 'sampleRateMs' ], axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and give them a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frames for mixed loaded.\n",
      "Data Frame for walking 1 loaded.\n",
      "Data Frame for walking 2 loaded.\n",
      "Data Frame for walking 3 loaded.\n",
      "Data Frame for walking 4 loaded.\n",
      "Data Frame for push ups 1 loaded.\n",
      "Data Frame for push ups 2 loaded.\n",
      "Data Frame for push ups 3 loaded.\n",
      "Data Frame for push ups 4 loaded.\n",
      "Data Frame for push ups 5 loaded.\n",
      "Data Frame for jumping jacks 1 loaded.\n",
      "Data Frame for jumping jacks 2 loaded.\n",
      "Data Frame for jumping jacks 3 loaded.\n",
      "Data Frame for jumping jacks 4 loaded.\n",
      "Data Frame for jumping jacks 5 loaded.\n"
     ]
    }
   ],
   "source": [
    "#load mixed data\n",
    "df_mixed_Acc, df_mixed_Gyr, df_mixed_Ori =loadDataFrames('mixed','data/MixedData/Accelerometer.csv', 'data/MixedData/Gyroscope.csv', 'data/MixedData/Orientation.csv')\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "#load data frames for walking\n",
    "#df_walk_Acc, df_walk_Gyr, df_walk_Ori =loadDataFrames('walking','data/NormalWalk/Accelerometer.csv', 'data/NormalWalk/Gyroscope.csv', 'data/NormalWalk/Orientation.csv')\n",
    "df_walk1 = loadJsonData('walking 1', 'data/NormalWalk/NormalWalk.json')\n",
    "\n",
    "#load data walk2\n",
    "#df_walk2_Acc, df_walk2_Gyr, df_walk2_Ori =loadDataFrames('walking 2','data/Walk2/Accelerometer.csv', 'data/Walk2/Gyroscope.csv', 'data/Walk2/Orientation.csv')\n",
    "df_walk2 = loadJsonData('walking 2', 'data/Walk2/Walk2.json')\n",
    "\n",
    "#load data walk3 Alex\n",
    "df_walk3 = loadJsonData('walking 3', 'data\\Alex_Rumstehen_-2023-05-02_15-30-58.json')\n",
    "\n",
    "#load data walk4 Alex\n",
    "df_walk4 = loadJsonData('walking 4', 'data\\Alex_Rumstehen_2-2023-05-23_14-53-09.json')\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "#load data frames for push ups\n",
    "#df_push_Acc, df_push_Gyr, df_push_Ori =loadDataFrames('push ups','data/PushUps/Accelerometer.csv', 'data/PushUps/Gyroscope.csv', 'data/PushUps/Orientation.csv')\n",
    "df_push1 = loadJsonData('push ups 1', 'data/PushUps/PushUps.json')\n",
    "\n",
    "#load data pushups2\n",
    "#df_push2_Acc, df_push2_Gyr, df_push2_Ori =loadDataFrames('push ups 2','data/PushUps2/Accelerometer.csv', 'data/PushUps2/Gyroscope.csv', 'data/PushUps2/Orientation.csv')\n",
    "df_push2 = loadJsonData('push ups 2', 'data/PushUps2/PushUps2.json')\n",
    "\n",
    "#load data pushups3 Alex\n",
    "df_push3 = loadJsonData('push ups 3', 'data/Alex_Push_Up_2-2023-05-23_15-04-54.json')\n",
    "\n",
    "#load data pushups4 Alex\n",
    "df_push4 = loadJsonData('push ups 4', 'data\\Alex_10_Liegestütz-2023-05-02_15-29-25.json')\n",
    "\n",
    "#load data pushups5 Pierre\n",
    "df_push5 = loadJsonData('push ups 5', 'data\\PushUps-pierre.json')\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "#load data frames for jumping jacks\n",
    "#df_JJ_Acc, df_JJ_Gyr, df_JJ_Ori =loadDataFrames('jumping jacks ','data/JJ_rightHand/Accelerometer.csv', 'data/JJ_rightHand/Gyroscope.csv', 'data/JJ_rightHand/Orientation.csv')\n",
    "df_JJ1 = loadJsonData('jumping jacks 1', 'data/JJ_rightHand/JJ1.json')\n",
    "\n",
    "#load data JJ2\n",
    "#df_JJ2_Acc, df_JJ2_Gyr, df_JJ2_Ori =loadDataFrames('jumping jacks 2','data/JJ2/Accelerometer.csv', 'data/JJ2/Gyroscope.csv', 'data/JJ2/Orientation.csv')\n",
    "df_JJ2 = loadJsonData('jumping jacks 2', 'data/JJ2/JJ2.json')\n",
    "\n",
    "#load data JJ3 Alex\n",
    "df_JJ3 = loadJsonData('jumping jacks 3', 'data/Alex_10_Hampelmänner-2023-05-02_15-30-18.json')\n",
    "\n",
    "#load data JJ4 Pierre\n",
    "df_JJ4 = loadJsonData('jumping jacks 4', 'data/JumpingsJacks-pierre-1.json')\n",
    "\n",
    "#load data JJ5 Pierre\n",
    "df_JJ5 = loadJsonData('jumping jacks 5', 'data/JumpingsJacks-pierre-2.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Json Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sensor', 'time', 'seconds_elapsed', 'z', 'y', 'x', 'relativeAltitude',\n",
       "       'pressure', 'batteryLevel', 'batteryState', 'lowPowerMode',\n",
       "       'brightness', 'lux', 'bearingAccuracy', 'speedAccuracy',\n",
       "       'verticalAccuracy', 'horizontalAccuracy', 'speed', 'bearing',\n",
       "       'altitude', 'longitude', 'latitude', 'version', 'device name',\n",
       "       'recording time', 'platform', 'appVersion', 'device id', 'sensors',\n",
       "       'sampleRateMs', 'qz', 'qy', 'qx', 'qw', 'roll', 'pitch', 'yaw'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walk1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walk1 = deleteSensorData(df_walk1)\n",
    "df_walk2 = deleteSensorData(df_walk2)\n",
    "df_JJ1 = deleteSensorData(df_JJ1)\n",
    "df_JJ2 = deleteSensorData(df_JJ2) \n",
    "df_push1 = deleteSensorData(df_push1)\n",
    "df_push2 = deleteSensorData(df_push2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n",
      "Spalten wurden erfolgreich entfernt.\n"
     ]
    }
   ],
   "source": [
    "#über liste iterieren ##TODO \n",
    "df_push1 = cleanDataJson(df_push1)\n",
    "df_push2 = cleanDataJson(df_push2)\n",
    "df_push3 = cleanDataJson(df_push3)\n",
    "df_push4 = cleanDataJson(df_push4)\n",
    "df_push5 = cleanDataJson(df_push5)\n",
    "df_JJ1 = cleanDataJson(df_JJ1)\n",
    "df_JJ2 = cleanDataJson(df_JJ2)\n",
    "df_JJ3 = cleanDataJson(df_JJ3)\n",
    "df_JJ4 = cleanDataJson(df_JJ4)\n",
    "df_JJ5 = cleanDataJson(df_JJ5)\n",
    "df_walk1 = cleanDataJson(df_walk1)\n",
    "df_walk2 = cleanDataJson(df_walk2)\n",
    "df_walk3 = cleanDataJson(df_walk3)\n",
    "df_walk4 = cleanDataJson(df_walk4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat DataFrames Walk\n",
    "df_walk1 = concatDataFrames('walking', df_walk_Acc, df_walk_Gyr, df_walk_Ori)\n",
    "\n",
    "#Concat DataFrames PushUps\n",
    "df_push1 = concatDataFrames('push ups', df_push_Acc, df_push_Gyr, df_push_Ori)\n",
    "\n",
    "#Concat DataFrames JumpingJacks\n",
    "df_JJ1 = concatDataFrames('jumping jacks', df_JJ_Acc, df_JJ_Gyr, df_JJ_Ori)\n",
    "\n",
    "#Concat DataFrames JumpingJacks2\n",
    "df_JJ2 = concatDataFrames('jumping jacks 2', df_JJ2_Acc, df_JJ2_Gyr, df_JJ2_Ori)\n",
    "\n",
    "#Concat DataFrames PushUps2\n",
    "df_push2 = concatDataFrames('push ups 2', df_push2_Acc, df_push2_Gyr, df_push2_Ori)\n",
    "\n",
    "#Concat DataFrames Walk2\n",
    "df_walk2 = concatDataFrames('walking 2', df_walk2_Acc, df_walk2_Gyr, df_walk2_Ori)\n",
    "\n",
    "\n",
    "\n",
    "#Concat Mixed DataFrames\n",
    "df_mixed = concatDataFrames('mixed', df_mixed_Acc, df_mixed_Gyr, df_mixed_Ori)\n",
    "df_mixed.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_push_Gyr.plot(x='time', y='z', kind='line')\n",
    "df_push_Gyr.plot(x='time', y='y', kind='line')\n",
    "df_push_Gyr.plot(x='time', y='x', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JJ3.plot(x='time', y='z', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Walk\n",
    "plotDataGyr(df_walk_Gyr, 'Gyroscope Walk')\n",
    "\n",
    "#Plot PushUps\n",
    "plotDataGyr(df_push_Gyr, 'Gyroscope PushUps')\n",
    "\n",
    "#Plot JumpingJacks\n",
    "plotDataGyr(df_JJ_Gyr, 'Gyroscope JumpingJacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accelerometer Data\n",
    "\n",
    "#Plot Walk\n",
    "plotDataAcc(df_walk_Acc, 'Accelerometer Walk')\n",
    "\n",
    "#Plot PushUps\n",
    "plotDataAcc(df_push_Acc, 'Accelerometer PushUps')\n",
    "\n",
    "#Plot JumpingJacks\n",
    "plotDataAcc(df_JJ_Acc, 'Accelerometer JumpingJacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Walk\n",
    "plotDataOri(df_walk_Ori, 'Orientation Walk')\n",
    "\n",
    "#Plot PushUps\n",
    "plotDataOri(df_push_Ori, 'Orientation PushUps')\n",
    "\n",
    "#Plot JumpingJacks\n",
    "plotDataOri(df_JJ_Ori, 'Orientation JumpingJacks')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KNN Classifikation**\n",
    "1. Label Data\n",
    "2. Concat Dataframes\n",
    "3. Split Data\n",
    "4. Train Model\n",
    "5. Predict\n",
    "6. Evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification with KNN\n",
    "#Function to label the data\n",
    "def getData(data, label):\n",
    "    data['label'] = label\n",
    "    return data\n",
    "\n",
    "#Label Data\n",
    "#Label Data Walk\n",
    "df_walk1 = getData(df_walk1, 'walk')\n",
    "df_walk2 = getData(df_walk2, 'walk')\n",
    "df_walk3 = getData(df_walk3, 'walk')\n",
    "df_walk4 = getData(df_walk4, 'walk')\n",
    "\n",
    "\n",
    "#Label Data PushUps\n",
    "df_push1 = getData(df_push1, 'pushups')\n",
    "df_push2 = getData(df_push2, 'pushups')\n",
    "df_push3 = getData(df_push3, 'pushups')\n",
    "df_push4 = getData(df_push4, 'pushups')\n",
    "df_push5 = getData(df_push5, 'pushups')\n",
    "\n",
    "#Label Data JumpingJacks\n",
    "df_JJ1 = getData(df_JJ1, 'jumpingjacks')\n",
    "df_JJ2 = getData(df_JJ2, 'jumpingjacks')\n",
    "df_JJ3 = getData(df_JJ3, 'jumpingjacks')\n",
    "df_JJ4 = getData(df_JJ4, 'jumpingjacks')\n",
    "df_JJ5 = getData(df_JJ5, 'jumpingjacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>seconds_elapsed</th>\n",
       "      <th>z</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>sensors</th>\n",
       "      <th>qz</th>\n",
       "      <th>qy</th>\n",
       "      <th>qx</th>\n",
       "      <th>qw</th>\n",
       "      <th>roll</th>\n",
       "      <th>pitch</th>\n",
       "      <th>yaw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.281794</td>\n",
       "      <td>-0.465686</td>\n",
       "      <td>0.086654</td>\n",
       "      <td>-0.091597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.291821</td>\n",
       "      <td>-0.216612</td>\n",
       "      <td>0.060574</td>\n",
       "      <td>-0.047214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.301851</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>0.038663</td>\n",
       "      <td>-0.008545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.311883</td>\n",
       "      <td>0.161940</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.056470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>0.224382</td>\n",
       "      <td>0.046912</td>\n",
       "      <td>0.119996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.331954</td>\n",
       "      <td>0.227283</td>\n",
       "      <td>0.064189</td>\n",
       "      <td>0.147190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.341991</td>\n",
       "      <td>0.232712</td>\n",
       "      <td>0.083530</td>\n",
       "      <td>0.145322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.352028</td>\n",
       "      <td>0.168754</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.138954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.362051</td>\n",
       "      <td>0.056705</td>\n",
       "      <td>0.071613</td>\n",
       "      <td>0.119926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.683041e+18</td>\n",
       "      <td>0.372072</td>\n",
       "      <td>-0.075214</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pushups</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  seconds_elapsed         z         y         x sensors  qz  \\\n",
       "0  1.683041e+18         0.281794 -0.465686  0.086654 -0.091597     NaN NaN   \n",
       "1  1.683041e+18         0.291821 -0.216612  0.060574 -0.047214     NaN NaN   \n",
       "2  1.683041e+18         0.301851  0.062978  0.038663 -0.008545     NaN NaN   \n",
       "3  1.683041e+18         0.311883  0.161940  0.031845  0.056470     NaN NaN   \n",
       "4  1.683041e+18         0.321918  0.224382  0.046912  0.119996     NaN NaN   \n",
       "5  1.683041e+18         0.331954  0.227283  0.064189  0.147190     NaN NaN   \n",
       "6  1.683041e+18         0.341991  0.232712  0.083530  0.145322     NaN NaN   \n",
       "7  1.683041e+18         0.352028  0.168754  0.073375  0.138954     NaN NaN   \n",
       "8  1.683041e+18         0.362051  0.056705  0.071613  0.119926     NaN NaN   \n",
       "9  1.683041e+18         0.372072 -0.075214  0.078500  0.048600     NaN NaN   \n",
       "\n",
       "   qy  qx  qw  roll  pitch  yaw    label  \n",
       "0 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "1 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "2 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "3 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "4 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "5 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "6 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "7 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "8 NaN NaN NaN   NaN    NaN  NaN  pushups  \n",
       "9 NaN NaN NaN   NaN    NaN  NaN  pushups  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot json data\n",
    "df_push4.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Concat Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat DataFrames\n",
    "df = pd.concat([df_walk1, df_push1, df_JJ1], axis=0)\n",
    "df_test = pd.concat([df_JJ2, df_push2, df_walk2], axis=0)\n",
    "\n",
    "#Short Df_test for predciton\n",
    "df_test= df_test.head(1517)\n",
    "\n",
    "\n",
    "\n",
    "#Fill NaN Values with propagation\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df_test.fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#kein random split sondern spezifizieren\n",
    "#erste 70% train, letzte 30% test\n",
    "#fünf trainings df und quasi im train nur die ersten 3 und die zwei anderen dann als test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop sensor column\n",
    "df_push4 = df_push4.drop(columns=['sensor'])\n",
    "df_push5 = df_push5.drop(columns=['sensor'])\n",
    "df_JJ3 = df_JJ3.drop(columns=['sensor'])\n",
    "df_JJ4 = df_JJ4.drop(columns=['sensor'])\n",
    "df_JJ5 = df_JJ5.drop(columns=['sensor'])\n",
    "df_walk3 = df_walk3.drop(columns=['sensor'])\n",
    "df_walk4 = df_walk4.drop(columns=['sensor'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat all Dataframes into one\n",
    "df = pd.concat([df_walk1, df_walk2, df_push1, df_push2, df_push3, df_JJ1, df_JJ2, df_JJ3], axis=0)\n",
    "df_test = pd.concat([df_walk3, df_walk4, df_push4, df_push5, df_JJ4, df_JJ5], axis=0)\n",
    "\n",
    "#Fill NaN Values with propagation\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df_test.fillna(method='ffill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test: ', len(df_test))\n",
    "print('Df: ', len(df))\n",
    "\n",
    "df_test.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: Marvin\n",
    "#gemischten Datensatz vlt mal testen, weiß noch nicht genau wie ich den einbauen soll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.head(10)\n",
    "df_test.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data erste 70% train, letzte 30% test\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle= False, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sensor'], axis=1, inplace=True)\n",
    "\n",
    "# muss die daten aggregieren und zeitfenster statt zeitpunkte nehmen \n",
    "# damit kann ich dann die daten klassifizieren \n",
    "# große Dataframes in kleine Dataframes splitten und dann die kleinen Dataframes klassifizieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Training Data\n",
    "def showXTrainingData(data):\n",
    "  print(data.shape)\n",
    "  print(data.columns)\n",
    "  plt.plot(data['z'], color='red', marker='.')#\n",
    "  plt.plot(data['y'], color='blue', marker='.')#\n",
    "  plt.plot(data['x'], color='green', marker='.')#\n",
    "  plt.plot(data['qz'], color='yellow', marker='.')#\n",
    "  plt.plot(data['qy'], color='black', marker='.')#\n",
    "  plt.plot(data['qx'], color='orange', marker='.')#\n",
    "  plt.plot(data['qw'], color='pink', marker='.')#\n",
    "  plt.plot(data['roll'], color='purple', marker='.')#\n",
    "  plt.xlabel('time')\n",
    "  plt.ylabel('x,y,z,qz,qy,qx,qw,roll')\n",
    "  plt.legend(['z', 'y', 'x', 'qz', 'qy', 'qx', 'qw', 'roll'])\n",
    "  plt.title('Train Data')\n",
    "  plt.show()\n",
    "\n",
    "showXTrainingData(X_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Accelerometer|Gravity|Gyroscope|Orientation|Magnetometer|Barometer|Location|Microphone|Light|Battery|Brightness|Annotation|TotalAcceleration|MagnetometerUncalibrated|GyroscopeUncalibrated|AccelerometerUncalibrated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#KNN\u001b[39;00m\n\u001b[0;32m      2\u001b[0m knn \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m knn\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\marvi\\anaconda3\\envs\\ML4B-App\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 215\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\marvi\\anaconda3\\envs\\ML4B-App\\lib\\site-packages\\sklearn\\neighbors\\_base.py:454\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 454\u001b[0m         X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    455\u001b[0m             X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    456\u001b[0m         )\n\u001b[0;32m    458\u001b[0m     \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    459\u001b[0m         \u001b[39m# Classification targets require a specific format\u001b[39;00m\n\u001b[0;32m    460\u001b[0m         \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\marvi\\anaconda3\\envs\\ML4B-App\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\marvi\\anaconda3\\envs\\ML4B-App\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\marvi\\anaconda3\\envs\\ML4B-App\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marvi\\anaconda3\\envs\\ML4B-App\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\marvi\\anaconda3\\envs\\ML4B-App\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Accelerometer|Gravity|Gyroscope|Orientation|Magnetometer|Barometer|Location|Microphone|Light|Battery|Brightness|Annotation|TotalAcceleration|MagnetometerUncalibrated|GyroscopeUncalibrated|AccelerometerUncalibrated'"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#shuffle data and then split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "\n",
    "#Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ', accuracy * 100, '%')\n",
    "\n",
    "#Recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('Recall: ', recall * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data Mixed\n",
    "X_mixed = df_mixed.drop(['label'], axis=1)\n",
    "y_mixed = df_mixed['label']\n",
    "X_train_mixed, X_test_mixed, y_train_mixed, y_test_mixed = train_test_split(X_mixed, y_mixed, test_size=0.3)\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_mixed = knn.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonstiges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export Model into Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle wird benutzt um das trainierte Modell zu speichern und dann in streamlit zu laden, dort können wir es dann auf den datensatz anwenden\n",
    "pkl.dump(knn, open('knn.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lösung von ChatGpt, leider nicht so einfach..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "training_data = df.drop(['label'], axis=1)\n",
    "training_labels = df['label']\n",
    "\n",
    "# Sensordaten in eine zweidimensionale Form umwandeln\n",
    "training_data = training_data.reshape(training_data.shape[0], -1)\n",
    "\n",
    "\n",
    "# KNN-Modell erstellen und trainieren\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "knn.fit(training_data, training_labels)\n",
    "\n",
    "# Sensordaten für eine neue Instanz\n",
    "new_data = df_test\n",
    "new_data = new_data.reshape(1, -1)\n",
    "\n",
    "# Vorhersage für die neue Instanz\n",
    "prediction = knn.predict([new_data])\n",
    "\n",
    "# Wahrscheinlichkeiten der Vorhersagen\n",
    "probabilities = knn.predict_proba([new_data])\n",
    "\n",
    "# Index der vorhergesagten Klasse\n",
    "predicted_class_index = prediction[0]\n",
    "\n",
    "# Wahrscheinlichkeit der vorhergesagten Klasse\n",
    "predicted_class_probability = probabilities[0][predicted_class_index]\n",
    "\n",
    "# Klassenbezeichnungen\n",
    "class_names = ['Jumping Jacks', 'Pushups', 'Laufen']\n",
    "\n",
    "# Ergebnis ausgeben\n",
    "result = f\"Mit {predicted_class_probability*100:.2f}% Sicherheit hat die Person {class_names[predicted_class_index]} gemacht.\"\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4B-App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
